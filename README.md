# ðŸŒ¤ï¸ Weather Data Pipeline â€“ Kafka + PostgreSQL + Streamlit

Un pipeline de donnÃ©es en temps rÃ©el qui collecte les donnÃ©es mÃ©tÃ©orologiques via lâ€™API OpenWeatherMap, les transmet via **Apache Kafka (broker + topic)**, les stocke dans **PostgreSQL**, et les visualise dans un **dashboard interactif Streamlit** avec **graphiques Plotly**.

---

## ðŸš€ FonctionnalitÃ©s

- **Producer** : Script Python qui rÃ©cupÃ¨re la mÃ©tÃ©o de 14 villes franÃ§aises via **OpenWeatherMap API** et envoie les donnÃ©es Ã  Kafka
- **Kafka** : Utilisation dâ€™un **broker Kafka** et dâ€™un **topic** (`weather_data`) pour le streaming des messages
- **Consumer** : Script Python qui lit les messages depuis Kafka et stocke les donnÃ©es dans **PostgreSQL** (une ligne par ville, mise Ã  jour automatique)
- **Dashboard** : Interface **Streamlit** avec visualisations interactives (**Plotly**), filtres dynamiques et export CSV
- **Monitoring** : **pgAdmin** intÃ©grÃ© pour explorer et requÃªter la base de donnÃ©es
- **CI** : Validation automatique via **GitHub Actions** (build Docker, vÃ©rification syntaxe Python)

---

## ðŸ—ï¸ Architecture

```mermaid
graph LR
A[OpenWeatherMap API] --> B(Producer Python)
B --> C{Kafka Broker<br><small>Topic: weather_data</small>}
C --> D(Consumer Python)
D --> E[(PostgreSQL)]
E --> F[Streamlit + Plotly]
E --> G[pgAdmin]
